{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from network_control.metrics import modal_control,ave_control #install network_control library https://github.com/BassettLab/nctpy\n",
    "from network_control.utils import matrix_normalization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "from ipynb.fs.full.func_lib import adjust_dist\n",
    "from ipynb.fs.full.func_lib import get_class_labels\n",
    "from ipynb.fs.full.func_lib import get_cluster_labels\n",
    "from ipynb.fs.full.func_lib import get_consensus_matrix\n",
    "from ipynb.fs.full.func_lib import plot_clustered_cmat\n",
    "from ipynb.fs.full.func_lib import coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['k_in', 'k_out', 'hubs', 'authorities', 'incloseness',\n",
    "       'outcloseness', 't1', 't2', 'betweenness_centrality',\n",
    "       'eigenvector_centrality', 'degree_centrality', 'clustering_coefficient',\n",
    "       'modal_controllability', 'average_controllability', 'neighbour_degree',\n",
    "       'strength']\n",
    "\n",
    "features_combination = coeffs(len(feature_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(topic):\n",
    "    \n",
    "    df_all = pd.read_csv('Node_measures_'+topic+'.csv',index_col=0)\n",
    "\n",
    "    df_all = adjust_dist(df_all, feature_list)\n",
    "\n",
    "    df_all = df_all[selected_features]\n",
    "\n",
    "    measure_list = df_all.columns.values[1:].reshape((2,len(selected_ids)))\n",
    "    measure_list = df_all.columns.values[1:]\n",
    "\n",
    "\n",
    "    X = df_all[measure_list].values.astype(float)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pca_transform(X):\n",
    "    \n",
    "    X_sc = StandardScaler().fit_transform(X)\n",
    "    pca = PCA()\n",
    "    X_pc = pca.fit_transform(X_sc)\n",
    "    \n",
    "    if np.all(pca.components_[0] < 0) or np.all(pca.components_[0] > 0):\n",
    "        if ((np.all(pca.components_[1,0:3] < 0) & np.all(pca.components_[1,3:6] > 0)) \n",
    "                    or (np.all(pca.components_[1,0:3] > 0) & np.all(pca.components_[1,3:6] < 0))):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43399327",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_topics = ['ukraine','covid','costofliving','brexit']\n",
    "\n",
    "selected_features_list = []\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for arr in features_combination:\n",
    "    if (arr.sum()>2):\n",
    "        selected_ids = np.where(arr == 1)[0]\n",
    "        selected_features = [feature_list[index] for index in selected_ids] + ['null_'+feature_list[index] for index in selected_ids]\n",
    "        selected_features.insert(0,'Node')\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            \n",
    "            count_topics = 0\n",
    "            \n",
    "            for topic in list_of_topics:\n",
    "            \n",
    "                if check_pca_transform(get_data(topic)):\n",
    "                \n",
    "                    count_topics +=1\n",
    "            \n",
    "            if count_topics == 4:\n",
    "                selected_features_list.append(selected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7374dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.DataFrame()\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for selected_ids in selected_features_list:\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        \n",
    "        df_final = pd.DataFrame()\n",
    "\n",
    "        for topic in list_of_topics:\n",
    "\n",
    "            selected_features = [feature_list[index] for index in selected_ids] + ['null_'+feature_list[index] for index in selected_ids]\n",
    "\n",
    "            selected_features.insert(0,'Node')\n",
    "\n",
    "            df_all = pd.read_csv('Node_measures_'+topic+'.csv',index_col=0)\n",
    "\n",
    "            df_all = adjust_dist(df_all, feature_list)\n",
    "\n",
    "            df_all = df_all[selected_features]\n",
    "\n",
    "            measure_list = df_all.columns.values[1:].reshape((2,len(selected_ids)))\n",
    "            measure_list = df_all.columns.values[1:]\n",
    "\n",
    "\n",
    "            X = df_all[measure_list].values.astype(float)\n",
    "\n",
    "            cluster_labels = get_cluster_labels(X,num_clusters=3,num_sims=50)\n",
    "\n",
    "            df_all['Cluster'] = cluster_labels[0]\n",
    "\n",
    "            X_sc = StandardScaler().fit_transform(X)\n",
    "            pca = PCA()\n",
    "            X_pc = pca.fit_transform(X_sc)\n",
    "\n",
    "            df_pc = pd.DataFrame(data=X_pc[:,:2],columns=['Inherent', 'Active'])\n",
    "\n",
    "            if np.all(pca.components_[0] < 0):\n",
    "                df_pc['Inherent'] = -1*df_pc['Inherent']\n",
    "\n",
    "            df_pc['Node'] = df_all['Node']\n",
    "\n",
    "            df = df_all.merge(df_pc, on = 'Node')\n",
    "\n",
    "            cluster_mean = []\n",
    "\n",
    "            for cluster_id in range(3):\n",
    "                \n",
    "                cluster_mean.append(df.loc[df['Cluster']==cluster_id]['Inherent'].mean())\n",
    "                \n",
    "            sorted_clusters = list(np.argsort(cluster_mean))\n",
    "\n",
    "            nodal_cluster = sorted_clusters[2]\n",
    "            \n",
    "            df['topic'] = topic\n",
    "\n",
    "            if topic == list_of_topics[0]:\n",
    "                df_final = df.loc[df['Cluster']==nodal_cluster]\n",
    "            else:\n",
    "                df_final = pd.concat([df_final,df.loc[df['Cluster']==nodal_cluster]])\n",
    "\n",
    "\n",
    "        df_clusters.at[idx,'features'] = str(measure_list)\n",
    "\n",
    "\n",
    "        ukr_list = list(df_final.loc[df_final['topic']=='ukraine']['Node'])\n",
    "        cvd_list = list(df_final.loc[df_final['topic']=='covid']['Node'])\n",
    "        col_list = list(df_final.loc[df_final['topic']=='costofliving']['Node'])\n",
    "        brx_list = list(df_final.loc[df_final['topic']=='brexit']['Node'])\n",
    "\n",
    "        l = [ukr_list, cvd_list, col_list, brx_list]\n",
    "\n",
    "        df_clusters.at[idx,'shared_nodes'] = len(set(l[0]).intersection(*l))\n",
    "        idx +=1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
