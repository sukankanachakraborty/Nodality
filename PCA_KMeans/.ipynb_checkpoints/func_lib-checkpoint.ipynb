{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from network_control.metrics import modal_control,ave_control #install network_control library https://github.com/BassettLab/nctpy\n",
    "from network_control.utils import matrix_normalization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f78204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network(fileroot): \n",
    "    \n",
    "    df = pd.read_csv(f'Edge_lists/adj_list_{fileroot}.csv')\n",
    "    df['Weight'] = df['Weight']/df['Weight'].max()\n",
    "    G = nx.from_pandas_edgelist(df,source='Source',target='Target',\n",
    "                                edge_attr='Weight',create_using=nx.DiGraph())\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32870f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def controllability(G):\n",
    "    net = nx.to_numpy_array(G)\n",
    "    net = matrix_normalization(net,'discrete')\n",
    "    nodes = list(G.nodes())\n",
    "    mc = modal_control(net)\n",
    "    ac = ave_control(net)\n",
    "    mc_dict = dict(zip(nodes,mc))\n",
    "    ac_dict = dict(zip(nodes,ac))\n",
    "    return mc_dict,ac_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032bf531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_measures(G):\n",
    "    nbc_dict = nx.betweenness_centrality(G,weight='distance',normalized=False)\n",
    "    nec_dict = nx.eigenvector_centrality(G,max_iter=2000,weight='weight')\n",
    "    ndc_dict = nx.degree_centrality(G)\n",
    "    nclus_dict = nx.clustering(G,weight='weight')\n",
    "    mc_dict,ac_dict = controllability(G)\n",
    "    neigh_dict = nx.average_neighbor_degree(G)\n",
    "    str_dict = dict(G.degree(weight='weight'))\n",
    "    dicts = [nbc_dict,nec_dict,ndc_dict,nclus_dict,ac_dict,mc_dict,neigh_dict,str_dict]\n",
    "    measures = ['betweenness_centrality','eigenvector_centrality',\n",
    "                'degree_centrality','clustering_coefficient',\n",
    "                'average_controllability','modal_controllability',\n",
    "                'neighbour_degree','strength']\n",
    "\n",
    "    dfs = []\n",
    "    for measure,d in zip(measures,dicts):\n",
    "        dfm = pd.DataFrame.from_dict(d,'index')\n",
    "        dfm.columns=[measure]\n",
    "        dfs.append(dfm)\n",
    "    \n",
    "    df = pd.concat(dfs,axis=1,ignore_index=False)\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['Node']+measures\n",
    "    return df,measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27711ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_dist(df_all, measure_list):\n",
    "    \n",
    "    measure_list.remove('Node')\n",
    "    \n",
    "    for measure in measure_list:\n",
    "        if 'controllability' not in measure:\n",
    "            df_all[measure] = np.log(df_all[measure])\n",
    "        else:\n",
    "            fitted_data,_ = boxcox(df_all[measure].values)\n",
    "            df_all[measure] = fitted_data\n",
    "        \n",
    "    df_all = df_all.replace([-np.inf,np.inf],np.nan)\n",
    "    df_all = df_all.dropna()\n",
    "    \n",
    "    list_of_measures = ['eigenvector_centrality','hubs','authorities','incloseness','outcloseness']\n",
    "    \n",
    "    for measure in measure_list:\n",
    "        if 'eigenvector' in measure:\n",
    "            df_all = df_all.loc[np.logical_and(df_all['eigenvector_centrality']>-20,df_all['null_eigenvector_centrality']>-20)]\n",
    "        elif 'hubs' in measure:\n",
    "            df_all = df_all.loc[df_all['hubs']>-12]\n",
    "        elif 'authorities' in measure:\n",
    "            df_all = df_all.loc[df_all['authorities']>-15]\n",
    "        elif 'incloseness' in measure:\n",
    "            df_all = df_all.loc[df_all['incloseness']>-12.5]\n",
    "        elif 'outcloseness' in measure:\n",
    "            df_all = df_all.loc[df_all['outcloseness']>-12.5]\n",
    "            \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_labels():\n",
    "    class_labels_mp = pd.read_csv('labels/labels_mps.csv')\n",
    "    class_labels_jou = pd.read_csv('labels/labels_journalists.csv')\n",
    "    class_labels_mp['label'].loc[np.logical_and(class_labels_mp['label']==0,class_labels_mp['c2']!='Conservative')] = 3\n",
    "    class_labels_jou['label']+=1\n",
    "    \n",
    "    class_labels = pd.concat([class_labels_mp[['username','label']],class_labels_jou[['username','label']]],axis=0,ignore_index=True)\n",
    "    \n",
    "    class_labels.columns = ['Node','Label']\n",
    "    return class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_labels(X, num_clusters ,num_sims):\n",
    "    cluster_labels = []\n",
    "#     print(\"Clustering\")\n",
    "    for sim in range(num_sims):\n",
    "        clf = KMeans(n_clusters= num_clusters, init='random', n_init=300)\n",
    "        labels = clf.fit_predict(X)\n",
    "        cluster_labels.append(labels)\n",
    "    cluster_labels = np.array(cluster_labels)\n",
    "    return cluster_labels\n",
    "\n",
    "def get_consensus_matrix(cluster_labels):\n",
    "    num_nodes = len(cluster_labels[0])\n",
    "    mat = np.zeros((num_nodes,num_nodes))\n",
    "    for i in tqdm(range(num_nodes)):\n",
    "        for j in range(num_nodes):\n",
    "            mat[i,j] = np.mean(cluster_labels[:,i]==cluster_labels[:,j])\n",
    "            mat[j,i] = mat[i,j]\n",
    "    return mat\n",
    "\n",
    "def plot_clustered_cmat(cmat):\n",
    "    dmat = 1-cmat\n",
    "    y = dmat[np.triu_indices(len(dmat), k=1)]\n",
    "    Z = linkage(y, method='single', optimal_ordering=True)\n",
    "    perm = np.ravel(Z[:, :2]).astype(np.int32)\n",
    "    perm = perm[perm < len(dmat)]\n",
    "    ordered = dmat[perm][:,perm]\n",
    "\n",
    "    plt.imshow(ordered,cmap='coolwarm',vmin=0,vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60506237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeffs(n_array, minimum=0):\n",
    "    \n",
    "#     \"\"\"A function that a list of all combinations of 1s and 0s given the number of 1s.\n",
    "# \n",
    "#     Args:\n",
    "#         n_array (int/float): number of ones/length of array.\n",
    "#         minimum (int/float): minimum number of ones considered.\n",
    "# \n",
    "#     Returns: \n",
    "#         list: list of arrays with combinations of 0s and 1s.\n",
    "#     \"\"\"\n",
    "\n",
    "    coeff_list = []\n",
    "    ITER_MAX = 100\n",
    "    n_array = int(n_array)\n",
    "\n",
    "    for ones in range(int(minimum), n_array+1):\n",
    "        coeffs_ = []\n",
    "        perm_ = np.zeros(n_array)\n",
    "        perm_[:ones] = 1\n",
    "        \n",
    "        iter_ = 0\n",
    "        while len(coeffs_) != math.comb(n_array, ones) and iter_ < ITER_MAX:\n",
    "            p = np.random.permutation(perm_)\n",
    "            bools_ = [np.array_equal(p, arr) for arr in coeffs_]\n",
    "            if sum(bools_) == 0:\n",
    "                coeffs_.append(p)\n",
    "            iter_ = iter_ + 1\n",
    "        coeff_list = coeff_list + coeffs_\n",
    "    return coeff_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
